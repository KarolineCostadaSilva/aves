{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-1.23.1-py3-none-any.whl (15.6 MB)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (4.8.3)\n",
      "Collecting docker>=4.0.0\n",
      "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Collecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (6.0.1)\n",
      "Collecting waitress\n",
      "  Downloading waitress-2.0.0-py3-none-any.whl (56 kB)\n",
      "Collecting Flask\n",
      "  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (1.19.2)\n",
      "Collecting sqlparse>=0.3.1\n",
      "  Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (21.3)\n",
      "Collecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.17.8.tar.gz (85 kB)\n",
      "Collecting click>=7.0\n",
      "  Using cached click-8.0.4-py3-none-any.whl (97 kB)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.23.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (1.1.5)\n",
      "Requirement already satisfied: pytz in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (2023.3.post1)\n",
      "Requirement already satisfied: scipy in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (1.5.4)\n",
      "Requirement already satisfied: alembic in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (1.7.7)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (1.4.50)\n",
      "Collecting protobuf>=3.7.0\n",
      "  Downloading protobuf-3.19.6-cp36-cp36m-win_amd64.whl (897 kB)\n",
      "Requirement already satisfied: requests>=2.17.3 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from mlflow) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from click>=7.0->mlflow) (0.4.5)\n",
      "Collecting pyjwt>=1.7.0\n",
      "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting oauthlib>=3.1.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from databricks-cli>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.26.7 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from databricks-cli>=0.8.7->mlflow) (1.26.18)\n",
      "Collecting pywin32==227\n",
      "  Downloading pywin32-227-cp36-cp36m-win_amd64.whl (9.1 MB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.0 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from gitpython>=2.1.0->mlflow) (4.1.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from requests>=2.17.3->mlflow) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from requests>=2.17.3->mlflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from requests>=2.17.3->mlflow) (3.6)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from alembic->mlflow) (5.4.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from alembic->mlflow) (1.1.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from sqlalchemy->mlflow) (2.0.2)\n",
      "Collecting Jinja2>=3.0\n",
      "  Using cached Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from Jinja2>=3.0->Flask->mlflow) (2.0.1)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from Werkzeug>=2.0->Flask->mlflow) (0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from packaging->mlflow) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\aldan\\anaconda3\\envs\\venv-robotic-grasp\\lib\\site-packages (from pandas->mlflow) (2.8.2)\n",
      "Collecting prometheus-client\n",
      "  Downloading prometheus_client-0.17.1-py3-none-any.whl (60 kB)\n",
      "Building wheels for collected packages: databricks-cli\n",
      "  Building wheel for databricks-cli (setup.py): started\n",
      "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.17.8-py3-none-any.whl size=145492 sha256=cd674567f770d2b79568c0620beb824075a7d36e2be4b9051be524d84659a5fd\n",
      "  Stored in directory: c:\\users\\aldan\\appdata\\local\\pip\\cache\\wheels\\03\\ea\\c8\\85739be513930e3d6f34649a8b9304c23d23172f39571d2fb7\n",
      "Successfully built databricks-cli\n",
      "Installing collected packages: Werkzeug, smmap, Jinja2, itsdangerous, click, websocket-client, tabulate, pywin32, pyjwt, prometheus-client, oauthlib, gitdb, Flask, waitress, sqlparse, querystring-parser, protobuf, prometheus-flask-exporter, gitpython, docker, databricks-cli, cloudpickle, mlflow\n",
      "  Attempting uninstall: pywin32\n",
      "    Found existing installation: pywin32 228\n",
      "    Uninstalling pywin32-228:\n",
      "      Successfully uninstalled pywin32-228\n",
      "Successfully installed Flask-2.0.3 Jinja2-3.0.3 Werkzeug-2.0.3 click-8.0.4 cloudpickle-2.2.1 databricks-cli-0.17.8 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.18 itsdangerous-2.0.1 mlflow-1.23.1 oauthlib-3.2.2 prometheus-client-0.17.1 prometheus-flask-exporter-0.23.0 protobuf-3.19.6 pyjwt-2.4.0 pywin32-227 querystring-parser-1.2.4 smmap-5.0.0 sqlparse-0.4.4 tabulate-0.8.10 waitress-2.0.0 websocket-client-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# System libraries\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do MLflow\n",
    "mlflow.set_experiment(\"classification_birds_efficientnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\\\Users\\\\Aldan\\\\Documents\\\\bird_classification\\\\100-bird-species\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e preparar o dataset\n",
    "def load_dataset(batch_size, data_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root=data_path + '\\\\train', transform=transform)\n",
    "    val_dataset = datasets.ImageFolder(root=data_path + '\\\\valid', transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(root=data_path + '\\\\test', transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Optuna, foi avaliado que o melhor modelo e os melhores hiperparâmetros foram:\n",
    "Trial 84 finished with value: 96.06870229007633 and parameters: {'architecture': 'EfficientNetB0', 'num_units': 1024, 'dropout_rate': 0.26805261168394723, 'learning_rate': 0.0005527843132235871}. Best is trial 84 with value: 96.06870229007633.\n",
    "Então repeti o mesmo modelo com os mesmo hiperparâmetros especificados no Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinamento do melhor modelo com melhores hiperparâmetros\n",
    "\n",
    "# Definindo o modelo personalizado\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_units, dropout_rate, num_classes):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "        in_features = self.base_model.get_classifier().in_features\n",
    "        self.base_model.reset_classifier(0)\n",
    "\n",
    "        # Descongelando as últimas camadas\n",
    "        for name, parameter in self.base_model.named_parameters():\n",
    "            if 'blocks' in name and int(name.split('.')[1]) >= 5:\n",
    "                parameter.requires_grad = True\n",
    "\n",
    "        # Camadas personalizadas com os melhores hiperparâmetros\n",
    "        self.new_layers = nn.Sequential(\n",
    "            nn.Linear(in_features, num_units),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(num_units),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_units, num_units // 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(num_units // 2),\n",
    "            nn.Linear(num_units // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.new_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de Treinamento e Avaliação\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs, device):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}%')\n",
    "\n",
    "        mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "        mlflow.log_metric(\"val_accuracy\", val_accuracy, step=epoch)\n",
    "\n",
    "    return train_loss, val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU is NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.7048035259161032, Validation Loss: 0.20657315109742852, Validation Accuracy: 95.26717557251908%\n",
      "Epoch 2, Train Loss: 0.24952891094920535, Validation Loss: 0.11552301169055082, Validation Accuracy: 97.32824427480917%\n",
      "Epoch 3, Train Loss: 0.11454417725608712, Validation Loss: 0.09825687585455342, Validation Accuracy: 97.09923664122137%\n",
      "Epoch 4, Train Loss: 0.06230563949528997, Validation Loss: 0.09588073689643885, Validation Accuracy: 97.55725190839695%\n",
      "Epoch 5, Train Loss: 0.03784968656228474, Validation Loss: 0.1003006163334315, Validation Accuracy: 97.63358778625954%\n",
      "Epoch 6, Train Loss: 0.024817665897805426, Validation Loss: 0.09362123060933167, Validation Accuracy: 97.55725190839695%\n",
      "Epoch 7, Train Loss: 0.0177147604837294, Validation Loss: 0.11349890893857596, Validation Accuracy: 97.40458015267176%\n",
      "Epoch 8, Train Loss: 0.014479046307744945, Validation Loss: 0.10874568661192159, Validation Accuracy: 97.44274809160305%\n",
      "Epoch 9, Train Loss: 0.012054186241617902, Validation Loss: 0.10858631998754147, Validation Accuracy: 97.55725190839695%\n",
      "Epoch 10, Train Loss: 0.00973736241808872, Validation Loss: 0.10624711481636395, Validation Accuracy: 97.90076335877863%\n",
      "Epoch 11, Train Loss: 0.008948946794694304, Validation Loss: 0.10252988960360754, Validation Accuracy: 97.90076335877863%\n",
      "Epoch 12, Train Loss: 0.007801793419973061, Validation Loss: 0.10032692597398148, Validation Accuracy: 97.82442748091603%\n",
      "Epoch 13, Train Loss: 0.005903205919518466, Validation Loss: 0.09866776772238464, Validation Accuracy: 97.86259541984732%\n",
      "Epoch 14, Train Loss: 0.005937773864744403, Validation Loss: 0.11006399140050478, Validation Accuracy: 97.86259541984732%\n",
      "Epoch 15, Train Loss: 0.0047729411973732845, Validation Loss: 0.10398574128215309, Validation Accuracy: 97.74809160305344%\n",
      "Epoch 16, Train Loss: 0.004606689744678354, Validation Loss: 0.1292948403911507, Validation Accuracy: 97.48091603053435%\n",
      "Epoch 17, Train Loss: 0.005008370443517902, Validation Loss: 0.10537864574427835, Validation Accuracy: 97.63358778625954%\n",
      "Epoch 18, Train Loss: 0.00429093720688136, Validation Loss: 0.10122528050691826, Validation Accuracy: 97.82442748091603%\n",
      "Epoch 19, Train Loss: 0.0044714312635733226, Validation Loss: 0.10960407650440529, Validation Accuracy: 97.97709923664122%\n",
      "Epoch 20, Train Loss: 0.0035239116941463153, Validation Loss: 0.10820695780319334, Validation Accuracy: 98.2442748091603%\n",
      "Epoch 21, Train Loss: 0.0042931109826054815, Validation Loss: 0.1179219599299558, Validation Accuracy: 97.59541984732824%\n",
      "Epoch 22, Train Loss: 0.0041410107390495825, Validation Loss: 0.12526058658774517, Validation Accuracy: 97.67175572519083%\n",
      "Epoch 23, Train Loss: 0.0035420349161017148, Validation Loss: 0.10629437908902196, Validation Accuracy: 97.93893129770993%\n",
      "Epoch 24, Train Loss: 0.004168542429350495, Validation Loss: 0.12309204314369265, Validation Accuracy: 97.86259541984732%\n",
      "Epoch 25, Train Loss: 0.0027716692088405937, Validation Loss: 0.10926808114580615, Validation Accuracy: 97.86259541984732%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 25\n",
    "learning_rate = 0.0005527843132235871\n",
    "num_units = 1024\n",
    "dropout_rate = 0.26805261168394723\n",
    "num_classes = len(os.listdir(r\"C:\\\\Users\\\\Aldan\\\\Documents\\\\bird_classification\\\\100-bird-species\\\\test\"))\n",
    "train_loader, val_loader, test_loader = load_dataset(batch_size, data_path)\n",
    "\n",
    "model = CustomModel(num_units, dropout_rate, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    train_loss, val_loss, val_accuracy = train_model(model=model, train_loader=train_loader, val_loader=val_loader, criterion=criterion, optimizer=optimizer, epochs=epochs, device=device)\n",
    "\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\\\Users\\\\Aldan\\\\Documents\\\\bird_classification\\\\model_efficientnet.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em C:\\\\Users\\\\Aldan\\\\Documents\\\\bird_classification\\\\model_efficientnet.pth\n"
     ]
    }
   ],
   "source": [
    "# Salvando o modelo\n",
    "save_model(model, model_path)\n",
    "\n",
    "print(f\"Modelo salvo em {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): EfficientNet(\n",
       "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNormAct2d(\n",
       "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): SiLU(inplace=True)\n",
       "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn2): BatchNormAct2d(\n",
       "      1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (new_layers): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.26805261168394723, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Linear(in_features=512, out_features=524, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando o modelo treinado\n",
    "model.load_state_dict(torch.load(r\"C:\\\\Users\\\\Aldan\\\\Documents\\\\bird_classification\\\\model_efficientnet.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(outputs, labels, num_classes):\n",
    "    # Binarize labels for multi-class ROC AUC\n",
    "    labels_binarized = label_binarize(labels.cpu(), classes=np.arange(num_classes))\n",
    "\n",
    "    # Compute probabilities\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1).cpu().detach().numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels.cpu(), np.argmax(probabilities, axis=1))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels.cpu(), np.argmax(probabilities, axis=1), average='macro')\n",
    "\n",
    "    # ROC AUC per class, then average\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(labels_binarized, probabilities, multi_class='ovr')\n",
    "    except ValueError:\n",
    "        roc_auc = float('nan')  # ROC AUC might not be applicable for a specific batch\n",
    "\n",
    "    return accuracy, precision, recall, f1, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, num_classes, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_accuracy = []\n",
    "    all_precision = []\n",
    "    all_recall = []\n",
    "    all_f1 = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            accuracy, precision, recall, f1, roc_auc = calculate_metrics(outputs, labels, num_classes)\n",
    "            all_accuracy.append(accuracy)\n",
    "            all_precision.append(precision)\n",
    "            all_recall.append(recall)\n",
    "            all_f1.append(f1)\n",
    "\n",
    "    avg_accuracy = np.mean(all_accuracy)\n",
    "    avg_precision = np.mean(all_precision)\n",
    "    avg_recall = np.mean(all_recall)\n",
    "    avg_f1 = np.mean(all_f1)\n",
    "\n",
    "    return avg_accuracy, avg_precision, avg_recall, avg_f1\n",
    "\n",
    "# Avaliar o modelo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, test_loader, num_classes, device)\n",
    "\n",
    "# Log metrics with MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 1703018413993 0.9916158536585366 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\\\Users\\\\Aldan\\\\Documents\\\\bird_classification\\\\mlruns\\\\0\\\\c4551743e4594275be711686eb75b8d1\\\\metrics\\\\accuracy'\n",
    "\n",
    "# Abrir o arquivo para leitura\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "print(f\"Acurácia: {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703018413996 0.9647998935346498 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\\\Users\\\\Aldan\\\\Documents\\\\bird_classification\\\\mlruns\\\\0\\\\c4551743e4594275be711686eb75b8d1\\\\metrics\\\\f1_score'\n",
    "\n",
    "# Abrir o arquivo para leitura\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "print(f\"F1-Score: {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703018413994 0.9693428184281844 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\\\Users\\\\Aldan\\\\Documents\\\\bird_classification\\\\mlruns\\\\0\\\\c4551743e4594275be711686eb75b8d1\\\\metrics\\\\precision'\n",
    "\n",
    "# Abrir o arquivo para leitura\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "print(f\"Precisão: {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703018413995 0.9617039295392953 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\\\Users\\\\Aldan\\\\Documents\\\\bird_classification\\\\mlruns\\\\0\\\\c4551743e4594275be711686eb75b8d1\\\\metrics\\\\recall'\n",
    "\n",
    "# Abrir o arquivo para leitura\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "print(f\"Recall: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação das métricas:\n",
    "**Desempenho Global**: O modelo demonstra um desempenho excepcional em todas as métricas. Uma acurácia de mais de 99% é rara em muitos cenários de classificação, especialmente em problemas com um grande número de classes, como na classificação de imagens de pássaros.\n",
    "\n",
    "**Equilíbrio entre Precisão e Recall**: O F1-Score alto sugere um excelente equilíbrio entre precisão e recall. Isso indica que o modelo não só identifica corretamente a maioria das classes positivas (alta precisão), mas também captura a grande maioria das ocorrências positivas (alto recall)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
